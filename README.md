# ü§ñ MultiAgent Platform

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-green.svg)
![License](https://img.shields.io/badge/license-MIT-purple.svg)
![Status](https://img.shields.io/badge/status-Production%20Ready-brightgreen.svg)

**Plataforma de Orquestra√ß√£o Inteligente de Agentes com LLMs**

*Transform any data into actionable knowledge*

[Documenta√ß√£o](#-documenta√ß√£o) ‚Ä¢ [Instala√ß√£o](#-instala√ß√£o) ‚Ä¢ [Uso R√°pido](#-uso-r√°pido) ‚Ä¢ [Arquitetura](#-arquitetura) ‚Ä¢ [Contribui√ß√£o](#-contribui√ß√£o)

</div>

---

## üìã √çndice

- [Vis√£o Geral](#-vis√£o-geral)
- [Caracter√≠sticas](#-caracter√≠sticas)
- [Arquitetura](#-arquitetura)
- [Instala√ß√£o](#-instala√ß√£o)
- [Agentes Dispon√≠veis](#-agentes-dispon√≠veis)
- [Dashboard de Monitoramento](#-dashboard-de-monitoramento)
- [Problemas Enfrentados e Solu√ß√µes](#-problemas-enfrentados-e-solu√ß√µes)
- [Diagramas](#-diagramas)
- [API Reference](#-api-reference)
- [Contribui√ß√£o](#-contribui√ß√£o)
- [Licen√ßa](#-licen√ßa)

---

## üåü Vis√£o Geral

O **MultiAgent Platform** √© uma plataforma SaaS/AI de n√≠vel empresarial para orquestra√ß√£o inteligente de m√∫ltiplos agentes especializados. Desenvolvido para transformar qualquer tipo de dado em conhecimento acion√°vel.

### Conceito Central

```
üìÑ Anything ‚Üí üìù MarkItDown ‚Üí üß† Intelligence ‚Üí ‚ö° Action
```

O Markdown √© o formato can√¥nico universal que conecta todas as opera√ß√µes.

### Dores que Resolve

| Problema | Solu√ß√£o MultiAgent |
|----------|-------------------|
| **Dados fragmentados** | Convers√£o unificada para Markdown |
| **Scraping manual** | Agentes RPA automatizados |
| **M√∫ltiplos LLMs** | Orquestrador inteligente com roteamento |
| **Falta de observabilidade** | Dashboard em tempo real |
| **Escalabilidade** | Multi-inst√¢ncia paralela |
| **Retry manual** | Auto-healing autom√°tico |

---

## ‚ú® Caracter√≠sticas

### Core Features

- üîÑ **Multi-Instance Execution**: At√© 10 workers paralelos
- ü§ñ **8 Agentes Especializados**: RPA, LLM, CV, Data Science, etc.
- üìä **Dashboard Real-Time**: Monitoramento visual WebSocket
- üõ°Ô∏è **Auto-Healing**: Retry logic com exponential backoff
- üìù **MarkItDown Engine**: Convers√£o universal para Markdown
- üîç **Embeddings Vetoriais**: Busca sem√¢ntica com Qdrant
- üìà **Observabilidade**: Logs estruturados e m√©tricas

### Engines de Scraping

| Engine | Uso | Performance |
|--------|-----|-------------|
| **Playwright** | Sites JavaScript modernos | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Selenium** | Compatibilidade universal | ‚≠ê‚≠ê‚≠ê |
| **Requests** | Sites est√°ticos | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

---

## üèóÔ∏è Arquitetura

### Estrutura do Projeto

```
mult-agent/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ agents/                    # Agentes especializados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ computer_vision/       # Processamento de imagem
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_science/          # An√°lise de dados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding/             # Vetoriza√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_orchestrator/      # Orquestra√ß√£o LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ markitdown/            # Convers√£o Markdown
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ observability/         # Monitoramento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rpa/                   # Web scraping/automation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web_scraper.py     # Agente principal
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ invoice_processor.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ specialist/            # Agentes especializados
‚îÇ   ‚îú‚îÄ‚îÄ api/                       # REST API FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/                 # Interface visual
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web_monitor.py         # Dashboard WebSocket
‚îÇ   ‚îú‚îÄ‚îÄ data/                      # Dados processados
‚îÇ   ‚îú‚îÄ‚îÄ docs/                      # Documenta√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ docker/                    # Containeriza√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/                 # Pipelines de dados
‚îÇ   ‚îî‚îÄ‚îÄ vector_db/                 # Banco vetorial
‚îú‚îÄ‚îÄ logs/                          # Logs de execu√ß√£o
‚îú‚îÄ‚îÄ output/                        # Resultados exportados
‚îú‚îÄ‚îÄ requirements_rpa.txt           # Depend√™ncias RPA
‚îú‚îÄ‚îÄ run_web_scraper.py             # Runner interativo
‚îú‚îÄ‚îÄ test_web_scraper.py            # Testes r√°pidos
‚îî‚îÄ‚îÄ README.md                      # Este arquivo
```

### Diagrama de Fluxo

```mermaid
graph TB
    subgraph Input
        A[üìÑ PDF] --> M[MarkItDown]
        B[üñºÔ∏è Image] --> M
        C[üåê Web] --> M
        D[üìä Excel] --> M
    end
    
    M --> MD[üìù Markdown]
    MD --> E[Embedding Agent]
    E --> VDB[(Vector DB)]
    
    subgraph Agents
        RPA[ü§ñ RPA Agent]
        LLM[üß† LLM Orchestrator]
        CV[üëÅÔ∏è Computer Vision]
        DS[üìà Data Science]
    end
    
    VDB --> LLM
    RPA --> MD
    
    LLM --> OUT[‚ö° Action/Response]
```

---

## üíª Instala√ß√£o

### Requisitos

- Python 3.10+
- Node.js 18+ (para dashboard)
- Chrome/Chromium (para Playwright/Selenium)

### Instala√ß√£o R√°pida

```bash
# Clone o reposit√≥rio
git clone https://github.com/seu-usuario/mult-agent.git
cd mult-agent

# Crie ambiente virtual
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Instale depend√™ncias
pip install -r app/api/requirements.txt
pip install -r requirements_rpa.txt

# Instale Playwright browsers
playwright install chromium

# Configure vari√°veis de ambiente
copy .env.example .env
# Edite .env com suas API keys
```

### Vari√°veis de Ambiente

```env
# LLM APIs
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Vector DB
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Dashboard
DASHBOARD_PORT=8000
```

---

## ü§ñ Agentes Dispon√≠veis

### 1. RPA Web Scraper Agent

**Arquivo**: `app/agents/rpa/web_scraper.py`

O agente mais completo para automa√ß√£o web e extra√ß√£o de dados.

```python
from app.agents.rpa.web_scraper import WebScraperAgent, ScrapingTask, ScenarioType

# Criar agente com 10 inst√¢ncias paralelas
agent = WebScraperAgent(max_instances=10)

# Definir tarefas
tasks = [
    ScrapingTask(
        url="https://news.ycombinator.com/",
        scenario=ScenarioType.NEWS,
        selectors={"headline": ".titleline > a"}
    )
]

# Executar
results = await agent.execute_multi_instance(tasks)
```

**Cen√°rios suportados**:
- üõí E-commerce (produtos, pre√ßos)
- üì∞ News (artigos, headlines)
- üíº Jobs (vagas, sal√°rios)
- üí∞ Financial (stocks, crypto)
- üéØ Custom (seletores personalizados)

### 2. LLM Orchestrator Agent

**Arquivo**: `app/agents/llm_orchestrator/agent.py`

Roteamento inteligente entre m√∫ltiplos LLMs.

```python
from app.agents.llm_orchestrator.agent import agent

# Executar com estrat√©gia
result = await agent.route_and_execute(
    task="Analise este documento",
    context="...",
    strategy="quality"  # ou "speed", "balanced"
)
```

### 3. Embedding Agent

**Arquivo**: `app/agents/embedding/agent.py`

Vetoriza√ß√£o de documentos para busca sem√¢ntica.

### 4. MarkItDown Agent

**Arquivo**: `app/agents/markitdown/agent.py`

Convers√£o universal para Markdown.

### 5. Computer Vision Agent

**Arquivo**: `app/agents/computer_vision/agent.py`

Processamento de imagens e OCR.

### 6. Data Science Agent

**Arquivo**: `app/agents/data_science/agent.py`

An√°lise estat√≠stica e ML.

### 7. Observability Agent

**Arquivo**: `app/agents/observability/agent.py`

M√©tricas e monitoramento.

### 8. Specialist Agent

**Arquivo**: `app/agents/specialist/agent.py`

Agentes especializados por dom√≠nio.

---

## üìä Dashboard de Monitoramento

### Iniciar Dashboard

```bash
python -m app.dashboard.web_monitor
```

Acesse: **http://localhost:8000**

### Recursos do Dashboard

- üìà M√©tricas em tempo real (WebSocket)
- üìã Hist√≥rico de tarefas
- üîß Status de workers
- üìä Gr√°ficos de performance
- ‚ö†Ô∏è Alertas de erro

---

## üîß Problemas Enfrentados e Solu√ß√µes

### Problema 1: Import Circular

**Descri√ß√£o**: Erro de importa√ß√£o circular entre m√≥dulos de agentes.

**Solu√ß√£o**: 
- Reestrutura√ß√£o dos `__init__.py`
- Lazy imports onde necess√°rio
- Separa√ß√£o clara de responsabilidades

### Problema 2: Timeout em Sites JavaScript

**Descri√ß√£o**: Playwright falhava em sites com muito JS.

**Solu√ß√£o**:
```python
# Implementado wait_until="networkidle"
await page.goto(url, wait_until="networkidle", timeout=30000)

# Scroll progressivo para lazy loading
await self._scroll_page(page)
```

### Problema 3: Rate Limiting de APIs

**Descri√ß√£o**: Bloqueio por excesso de requests.

**Solu√ß√£o**:
```python
# Exponential backoff com tenacity
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
async def scrape():
    pass
```

### Problema 4: Detec√ß√£o de Bot

**Descri√ß√£o**: Sites bloqueavam scrapers autom√°ticos.

**Solu√ß√£o**:
- User-Agent rotation
- Headers customizados
- Comportamento humano (scroll, waits)
- Suporte a proxies

### Problema 5: Memory Leak com Browsers

**Descri√ß√£o**: Chrome consumia muita mem√≥ria.

**Solu√ß√£o**:
```python
# Context manager com cleanup garantido
async with async_playwright() as p:
    browser = await p.chromium.launch()
    try:
        # opera√ß√µes
    finally:
        await browser.close()  # sempre fecha
```

---

## üìê Diagramas

### Diagrama de Classes - Web Scraper

```mermaid
classDiagram
    class WebScraperAgent {
        +int max_instances
        +Queue task_queue
        +List results
        +execute_multi_instance(tasks)
        +export_results_to_json()
        +export_results_to_csv()
        +health_check()
    }
    
    class ScrapingTask {
        +str url
        +ScenarioType scenario
        +ScraperEngine engine
        +Dict selectors
        +int wait_time
    }
    
    class ScrapingResult {
        +str task_id
        +str url
        +Dict data
        +str status
        +float execution_time
    }
    
    class ScraperEngine {
        <<enumeration>>
        PLAYWRIGHT
        SELENIUM
        REQUESTS
    }
    
    class ScenarioType {
        <<enumeration>>
        ECOMMERCE
        NEWS
        JOBS
        FINANCIAL
        CUSTOM
    }
    
    WebScraperAgent --> ScrapingTask
    WebScraperAgent --> ScrapingResult
    ScrapingTask --> ScraperEngine
    ScrapingTask --> ScenarioType
```

### Diagrama de Sequ√™ncia - Scraping Flow

```mermaid
sequenceDiagram
    participant User
    participant Agent as WebScraperAgent
    participant Queue as TaskQueue
    participant Worker
    participant Engine as ScraperEngine
    participant Website
    
    User->>Agent: execute_multi_instance(tasks)
    Agent->>Queue: add tasks
    
    loop Para cada worker
        Agent->>Worker: start worker
        Worker->>Queue: get task
        Worker->>Engine: select engine
        Engine->>Website: request page
        Website-->>Engine: HTML response
        Engine->>Worker: extracted data
        Worker->>Agent: ScrapingResult
    end
    
    Agent-->>User: List[ScrapingResult]
```

---

## üìö API Reference

### WebScraperAgent

```python
class WebScraperAgent:
    """
    Agente RPA para web scraping multi-inst√¢ncia.
    
    Args:
        max_instances (int): N√∫mero m√°ximo de workers paralelos. Default: 5
    
    Methods:
        execute_multi_instance(tasks): Executa lista de tarefas em paralelo
        export_results_to_json(filename): Exporta resultados para JSON
        export_results_to_csv(filename): Exporta resultados para CSV
        health_check(): Retorna status do agente
    """
```

### ScrapingTask

```python
@dataclass
class ScrapingTask:
    """
    Defini√ß√£o de tarefa de scraping.
    
    Attributes:
        url (str): URL alvo para scraping
        scenario (ScenarioType): Tipo de cen√°rio (NEWS, ECOMMERCE, etc)
        engine (ScraperEngine): Engine a usar (PLAYWRIGHT, SELENIUM, REQUESTS)
        selectors (Dict): CSS selectors customizados
        wait_time (int): Tempo de espera em ms. Default: 5000
        scroll_to_bottom (bool): Se deve rolar p√°gina. Default: False
    """
```

---

## üß™ Testes

### Executar Teste R√°pido

```bash
python test_web_scraper.py
```

### Executar Runner Interativo

```bash
python run_web_scraper.py
```

---

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie branch de feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudan√ßas (`git commit -m 'Adiciona nova feature'`)
4. Push para branch (`git push origin feature/nova-feature`)
5. Abra Pull Request

### Padr√µes de C√≥digo

- **Python**: PEP8, Black formatter
- **Docstrings**: Google style
- **Commits**: Conventional Commits
- **Testes**: pytest

---

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a MIT License - veja [LICENSE](LICENSE) para detalhes.

---

## üë• Autores

- **MultiAgent Platform Team**

---

<div align="center">

**‚≠ê Se este projeto foi √∫til, considere dar uma estrela! ‚≠ê**

Made with ‚ù§Ô∏è by MultiAgent Platform Team

</div>
